# ğŸ› ï¸ é–‹ç™ºã‚¬ã‚¤ãƒ‰

Discord-Obsidian Memo Botã®é–‹ç™ºç’°å¢ƒæ§‹ç¯‰ã‹ã‚‰å®Ÿè£…ã¾ã§ã€é–‹ç™ºè€…å‘ã‘ã®åŒ…æ‹¬çš„ãªã‚¬ã‚¤ãƒ‰ã§ã™ã€‚

## ğŸ“‹ ç›®æ¬¡

1. [é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—](#é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—)
2. [ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®ç†è§£](#ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®ç†è§£)
3. [é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼](#é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼)
4. [ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«ã¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³](#ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«ã¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³)
5. [ãƒ†ã‚¹ãƒˆæˆ¦ç•¥](#ãƒ†ã‚¹ãƒˆæˆ¦ç•¥)
6. [ãƒ‡ãƒãƒƒã‚°æ‰‹æ³•](#ãƒ‡ãƒãƒƒã‚°æ‰‹æ³•)
7. [æ–°æ©Ÿèƒ½é–‹ç™ºãƒ•ãƒ­ãƒ¼](#æ–°æ©Ÿèƒ½é–‹ç™ºãƒ•ãƒ­ãƒ¼)
8. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–](#ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–)

## ğŸš€ é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### å¿…è¦ãªãƒ„ãƒ¼ãƒ«

```bash
# å¿…é ˆãƒ„ãƒ¼ãƒ«
python --version          # 3.13ä»¥ä¸Š
uv --version              # æœ€æ–°ç‰ˆ
git --version             # 2.20ä»¥ä¸Š
docker --version          # 20.10ä»¥ä¸Šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

# æ¨å¥¨ãƒ„ãƒ¼ãƒ«
code --version            # VS Code
curl --version            # HTTP ãƒ†ã‚¹ãƒˆç”¨
jq --version              # JSON å‡¦ç†ç”¨
```

### é–‹ç™ºç’°å¢ƒã®æ§‹ç¯‰

```bash
# 1. ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/kenvexar/discord-obsidian-memo-bot.git
cd discord-obsidian-memo-bot

# 2. é–‹ç™ºç”¨ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv sync --dev

# 3. pre-commitãƒ•ãƒƒã‚¯ã®è¨­å®š
uv run pre-commit install

# 4. ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
cp .env.example .env.development
```

### VS Codeè¨­å®š

`.vscode/settings.json`:
```json
{
    "python.interpreter": "./venv/bin/python",
    "python.linting.enabled": true,
    "python.linting.ruffEnabled": true,
    "python.formatting.provider": "ruff",
    "python.testing.pytestEnabled": true,
    "python.testing.pytestArgs": ["tests/"],
    "files.exclude": {
        "**/__pycache__": true,
        "**/*.pyc": true,
        ".mypy_cache": true,
        ".pytest_cache": true
    }
}
```

`.vscode/extensions.json`:
```json
{
    "recommendations": [
        "ms-python.python",
        "charliermarsh.ruff",
        "ms-python.mypy-type-checker",
        "ms-vscode.vscode-json",
        "redhat.vscode-yaml"
    ]
}
```

### é–‹ç™ºç”¨è¨­å®š

`.env.development`:
```env
# é–‹ç™ºç’°å¢ƒè¨­å®š
ENVIRONMENT=development
LOG_LEVEL=DEBUG
LOG_FORMAT=pretty

# ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ï¼ˆAPIã‚­ãƒ¼ä¸è¦ã§ãƒ†ã‚¹ãƒˆå¯èƒ½ï¼‰
ENABLE_MOCK_MODE=true
MOCK_DISCORD_ENABLED=true
MOCK_GEMINI_ENABLED=true
MOCK_GARMIN_ENABLED=true
MOCK_SPEECH_ENABLED=true

# ãƒ†ã‚¹ãƒˆç”¨Obsidianãƒœãƒ«ãƒˆ
OBSIDIAN_VAULT_PATH=./test_vault

# ãƒ†ã‚¹ãƒˆç”¨ãƒãƒ£ãƒ³ãƒãƒ«IDï¼ˆä»»æ„ã®å€¤ã§OKï¼‰
CHANNEL_INBOX=123456789012345678
CHANNEL_VOICE=123456789012345679
CHANNEL_TASKS=123456789012345680
```

## ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®ç†è§£

### ä¸»è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å½¹å‰²

```
src/
â”œâ”€â”€ bot/           # Discord ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å±¤
â”‚   â”œâ”€â”€ client.py     # ãƒ¡ã‚¤ãƒ³Botã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
â”‚   â”œâ”€â”€ handlers.py   # ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†
â”‚   â””â”€â”€ commands.py   # ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰
â”œâ”€â”€ ai/            # AIå‡¦ç†å±¤
â”‚   â”œâ”€â”€ processor.py  # AIåˆ†æã‚¨ãƒ³ã‚¸ãƒ³
â”‚   â””â”€â”€ models.py     # ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ obsidian/      # Obsidiançµ±åˆå±¤
â”‚   â”œâ”€â”€ file_manager.py    # ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œ
â”‚   â””â”€â”€ template_system.py # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
â”œâ”€â”€ config/        # è¨­å®šç®¡ç†
â”œâ”€â”€ utils/         # å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â””â”€â”€ main.py        # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ

tests/
â”œâ”€â”€ unit/          # å˜ä½“ãƒ†ã‚¹ãƒˆ
â”œâ”€â”€ integration/   # çµ±åˆãƒ†ã‚¹ãƒˆ
â””â”€â”€ fixtures/      # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿

docs/              # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
â”œâ”€â”€ user/          # ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘
â”œâ”€â”€ developer/     # é–‹ç™ºè€…å‘ã‘
â””â”€â”€ operations/    # é‹ç”¨è€…å‘ã‘
```

### é‡è¦ãªãƒ•ã‚¡ã‚¤ãƒ«

| ãƒ•ã‚¡ã‚¤ãƒ« | å½¹å‰² | é‡è¦åº¦ |
|----------|------|--------|
| `src/main.py` | ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ | â­â­â­ |
| `src/config/settings.py` | è¨­å®šç®¡ç† | â­â­â­ |
| `src/bot/client.py` | Discord Bot ãƒ¡ã‚¤ãƒ³ | â­â­â­ |
| `src/ai/processor.py` | AIå‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³ | â­â­â­ |
| `src/obsidian/file_manager.py` | ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç† | â­â­â­ |
| `pyproject.toml` | ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š | â­â­ |
| `.env.example` | ç’°å¢ƒå¤‰æ•°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ | â­â­ |

## ğŸ”„ é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### åŸºæœ¬çš„ãªé–‹ç™ºã‚µã‚¤ã‚¯ãƒ«

```bash
# 1. æ–°ã—ã„ãƒ–ãƒ©ãƒ³ãƒã®ä½œæˆ
git checkout -b feature/new-amazing-feature

# 2. ã‚³ãƒ¼ãƒ‰ã®å®Ÿè£…
# ... é–‹ç™ºä½œæ¥­ ...

# 3. ã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚¯
uv run ruff check src/ --fix
uv run ruff format src/
uv run mypy src/

# 4. ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
uv run pytest tests/unit/
uv run pytest tests/integration/

# 5. å¤‰æ›´ã®ã‚³ãƒŸãƒƒãƒˆ
git add .
git commit -m "feat: add amazing new feature"

# 6. ãƒ—ãƒƒã‚·ãƒ¥ã¨ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
git push origin feature/new-amazing-feature
```

### ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¦ç´„

[Conventional Commits](https://www.conventionalcommits.org/)ã«å¾“ã„ã¾ã™ï¼š

```bash
# æ©Ÿèƒ½è¿½åŠ 
git commit -m "feat: add voice memo processing"

# ãƒã‚°ä¿®æ­£
git commit -m "fix: resolve discord connection timeout"

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°
git commit -m "docs: update installation guide"

# ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°
git commit -m "refactor: optimize AI processing pipeline"

# ãƒ†ã‚¹ãƒˆè¿½åŠ 
git commit -m "test: add unit tests for message processor"

# ãƒ“ãƒ«ãƒ‰ãƒ»è¨­å®šå¤‰æ›´
git commit -m "build: update dependencies"
```

### ãƒ–ãƒ©ãƒ³ãƒæˆ¦ç•¥

```
main           # æœ¬ç•ªãƒªãƒªãƒ¼ã‚¹ç”¨
â”œâ”€â”€ develop    # é–‹ç™ºçµ±åˆãƒ–ãƒ©ãƒ³ãƒ
â”œâ”€â”€ feature/*  # æ–°æ©Ÿèƒ½é–‹ç™º
â”œâ”€â”€ bugfix/*   # ãƒã‚°ä¿®æ­£
â”œâ”€â”€ hotfix/*   # ç·Šæ€¥ä¿®æ­£
â””â”€â”€ release/*  # ãƒªãƒªãƒ¼ã‚¹æº–å‚™
```

## ğŸ¨ ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«ã¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³

### Python ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„

```python
# 1. å‹ãƒ’ãƒ³ãƒˆã®å¿…é ˆä½¿ç”¨
async def process_message(
    self,
    message: str,
    channel_id: int,
    user_id: Optional[int] = None
) -> ProcessingResult:
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ã—ã¦Obsidianã«ä¿å­˜ã™ã‚‹."""
    pass

# 2. docstring ã®è¨˜è¿°
class AIProcessor:
    """AIåˆ†æã‚¨ãƒ³ã‚¸ãƒ³.

    Gemini APIã‚’ä½¿ç”¨ã—ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®åˆ†æãƒ»åˆ†é¡ãƒ»è¦ç´„ã‚’è¡Œã†ã€‚
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã¨ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å†…è”µã€‚

    Attributes:
        api_key: Gemini APIã‚­ãƒ¼
        cache: å‡¦ç†çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        rate_limiter: APIå‘¼ã³å‡ºã—åˆ¶é™ç®¡ç†
    """

    def __init__(self, api_key: str, cache_size: int = 1000):
        """AIProcessorã‚’åˆæœŸåŒ–ã™ã‚‹.

        Args:
            api_key: Gemini APIã‚­ãƒ¼
            cache_size: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºä¸Šé™
        """
        pass

# 3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
try:
    result = await self.ai_processor.analyze(content)
except APIError as e:
    logger.error("AI analysis failed", error=str(e), content_length=len(content))
    raise ProcessingError(f"AI analysis failed: {e}") from e
except Exception as e:
    logger.exception("Unexpected error in AI processing")
    raise

# 4. ãƒ­ã‚°è¨˜éŒ²
logger.info(
    "Message processed successfully",
    user_id=message.author.id,
    channel_id=message.channel.id,
    processing_time=processing_time
)
```

### è¨­è¨ˆåŸå‰‡

1. **Single Responsibility**: 1ã¤ã®ã‚¯ãƒ©ã‚¹ãƒ»é–¢æ•°ã¯1ã¤ã®è²¬ä»»ã®ã¿
2. **Dependency Injection**: ä¾å­˜æ€§ã¯å¤–éƒ¨ã‹ã‚‰æ³¨å…¥
3. **Interface Segregation**: å°ã•ãç‰¹åŒ–ã—ãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
4. **Don't Repeat Yourself**: ã‚³ãƒ¼ãƒ‰ã®é‡è¤‡ã‚’é¿ã‘ã‚‹

```python
# Good: å˜ä¸€è²¬ä»»
class MessageAnalyzer:
    async def analyze_content(self, content: str) -> ContentAnalysis:
        pass

class MessageSaver:
    async def save_to_obsidian(self, analysis: ContentAnalysis) -> SaveResult:
        pass

# Good: ä¾å­˜æ€§æ³¨å…¥
class MessageProcessor:
    def __init__(
        self,
        analyzer: MessageAnalyzer,
        saver: MessageSaver
    ):
        self.analyzer = analyzer
        self.saver = saver
```

## ğŸ§ª ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### ãƒ†ã‚¹ãƒˆã®ç¨®é¡ã¨å®Ÿè¡Œ

```bash
# å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
uv run pytest

# ç‰¹å®šã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
uv run pytest tests/unit/test_ai_processing.py

# ç‰¹å®šã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
uv run pytest tests/unit/test_ai_processing.py::test_content_analysis

# ã‚«ãƒãƒ¬ãƒƒã‚¸ä»˜ãå®Ÿè¡Œ
uv run pytest --cov=src --cov-report=html

# ä¸¦åˆ—å®Ÿè¡Œ
uv run pytest -n auto

# è©³ç´°å‡ºåŠ›
uv run pytest -v -s
```

### ãƒ†ã‚¹ãƒˆã®æ›¸ãæ–¹

```python
# tests/unit/test_ai_processing.py
import pytest
from unittest.mock import AsyncMock, patch

from src.ai.processor import AIProcessor
from src.ai.models import ProcessingResult

class TestAIProcessor:
    @pytest.fixture
    def processor(self, mock_settings):
        return AIProcessor(mock_settings)

    @pytest.mark.asyncio
    async def test_content_analysis_success(self, processor):
        # Arrange
        content = "ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã€‚æ•£æ­©ã«è¡ŒããŸã„ã€‚"
        expected_tags = ["weather", "activity"]

        # Act
        with patch.object(processor.gemini_client, 'analyze') as mock_analyze:
            mock_analyze.return_value = ProcessingResult(
                summary="å¤©æ°—ã¨æ•£æ­©ã«ã¤ã„ã¦",
                tags=expected_tags,
                category="personal"
            )

            result = await processor.analyze_content(content)

        # Assert
        assert result.summary == "å¤©æ°—ã¨æ•£æ­©ã«ã¤ã„ã¦"
        assert result.tags == expected_tags
        assert result.category == "personal"
        mock_analyze.assert_called_once_with(content)

    @pytest.mark.asyncio
    async def test_content_analysis_api_error(self, processor):
        # Arrange
        content = "ãƒ†ã‚¹ãƒˆå†…å®¹"

        # Act & Assert
        with patch.object(processor.gemini_client, 'analyze') as mock_analyze:
            mock_analyze.side_effect = APIError("API limit exceeded")

            with pytest.raises(ProcessingError, match="AI analysis failed"):
                await processor.analyze_content(content)
```

### ãƒ¢ãƒƒã‚¯ã¨ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£

```python
# tests/conftest.py
import pytest
from unittest.mock import AsyncMock

@pytest.fixture
def mock_settings():
    settings = AsyncMock()
    settings.gemini_api_key = "test-api-key"
    settings.obsidian_vault_path = "/tmp/test-vault"
    settings.environment = "testing"
    return settings

@pytest.fixture
async def test_obsidian_manager(tmp_path):
    vault_path = tmp_path / "test_vault"
    vault_path.mkdir()

    from src.obsidian.file_manager import ObsidianFileManager
    manager = ObsidianFileManager(str(vault_path))
    await manager.initialize_vault()

    yield manager
```

## ğŸ› ãƒ‡ãƒãƒƒã‚°æ‰‹æ³•

### ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®æ´»ç”¨

```python
# é–‹ç™ºæ™‚ã®ãƒ­ã‚°è¨­å®š
import structlog

logger = structlog.get_logger(__name__)

async def debug_message_processing(self, message: str):
    logger.debug("Starting message processing", message_length=len(message))

    try:
        # AIåˆ†æ
        logger.debug("Calling AI analysis")
        analysis = await self.ai_processor.analyze(message)
        logger.info("AI analysis completed",
                   tags=analysis.tags,
                   category=analysis.category)

        # Obsidianä¿å­˜
        logger.debug("Saving to Obsidian", folder=analysis.category)
        result = await self.obsidian_manager.save(analysis)
        logger.info("Save completed", file_path=result.file_path)

    except Exception as e:
        logger.exception("Message processing failed",
                        error=str(e),
                        message_preview=message[:100])
        raise
```

### ãƒ‡ãƒãƒƒã‚°ç”¨ã‚³ãƒãƒ³ãƒ‰

```bash
# ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•
LOG_LEVEL=DEBUG uv run python -m src.main

# ç‰¹å®šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ‡ãƒãƒƒã‚°
PYTHONPATH=src python -c "
from src.ai.processor import AIProcessor
import asyncio

async def debug():
    processor = AIProcessor('test-key')
    result = await processor.analyze('ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸')
    print(result)

asyncio.run(debug())
"

# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒãƒƒã‚°
python -m pdb -c continue -m src.main
```

### ãƒ‡ãƒãƒƒã‚¬ãƒ¼è¨­å®š

VS Code launch.json:
```json
{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Discord Bot Debug",
            "type": "python",
            "request": "launch",
            "module": "src.main",
            "console": "integratedTerminal",
            "env": {
                "ENVIRONMENT": "development",
                "LOG_LEVEL": "DEBUG"
            }
        },
        {
            "name": "Run Tests",
            "type": "python",
            "request": "launch",
            "module": "pytest",
            "args": ["tests/unit/", "-v"],
            "console": "integratedTerminal"
        }
    ]
}
```

## ğŸš€ æ–°æ©Ÿèƒ½é–‹ç™ºãƒ•ãƒ­ãƒ¼

### 1. æ©Ÿèƒ½è¨­è¨ˆ

```python
# æ©Ÿèƒ½ä»•æ§˜æ›¸ (docs/features/new-feature.md)
"""
# æ–°æ©Ÿèƒ½: è‡ªå‹•ã‚¿ã‚°å­¦ç¿’

## æ¦‚è¦
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éå»ã®ã‚¿ã‚°ä»˜ã‘ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã€ã‚ˆã‚Šç²¾åº¦ã®é«˜ã„è‡ªå‹•ã‚¿ã‚°ä»˜ã‘ã‚’å®Ÿç¾

## è¦ä»¶
- éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã‚¿ã‚°ã®é–¢é€£æ€§ã‚’åˆ†æ
- æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ã‚ˆã‚‹ç¶™ç¶šå­¦ç¿’

## å®Ÿè£…è¨ˆç”»
1. ãƒ‡ãƒ¼ã‚¿åé›†æ©Ÿèƒ½ã®å®Ÿè£…
2. æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
3. äºˆæ¸¬APIã®å®Ÿè£…
4. ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ©Ÿèƒ½ã®å®Ÿè£…
"""
```

### 2. ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å®šç¾©

```python
# src/ai/models.py
from pydantic import BaseModel
from typing import List, Dict, Optional
from datetime import datetime

class TagLearningData(BaseModel):
    """ã‚¿ã‚°å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«."""
    content: str
    user_tags: List[str]
    ai_tags: List[str]
    feedback_score: Optional[float] = None
    created_at: datetime

class TagPrediction(BaseModel):
    """ã‚¿ã‚°äºˆæ¸¬çµæœ."""
    predicted_tags: List[str]
    confidence_scores: Dict[str, float]
    learning_source: str  # 'ml_model' or 'rule_based'
```

### 3. å®Ÿè£…

```python
# src/ai/tag_learner.py
class TagLearner:
    """è‡ªå‹•ã‚¿ã‚°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ."""

    def __init__(self, settings: Settings):
        self.settings = settings
        self.model: Optional[Any] = None
        self.training_data: List[TagLearningData] = []

    async def collect_training_data(self,
                                  content: str,
                                  user_tags: List[str],
                                  ai_tags: List[str]) -> None:
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã™ã‚‹."""
        data = TagLearningData(
            content=content,
            user_tags=user_tags,
            ai_tags=ai_tags,
            created_at=datetime.utcnow()
        )
        self.training_data.append(data)

        # ä¸€å®šæ•°è“„ç©ã•ã‚ŒãŸã‚‰è‡ªå‹•å­¦ç¿’
        if len(self.training_data) >= self.settings.auto_training_threshold:
            await self.train_model()

    async def train_model(self) -> None:
        """æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹."""
        logger.info("Starting model training",
                   data_count=len(self.training_data))

        # ç‰¹å¾´é‡æŠ½å‡º
        features, labels = self._prepare_training_data()

        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        self.model = await self._train_ml_model(features, labels)

        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        await self._save_model()

        logger.info("Model training completed")

    async def predict_tags(self, content: str) -> TagPrediction:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«å¯¾ã—ã¦ã‚¿ã‚°ã‚’äºˆæ¸¬ã™ã‚‹."""
        if not self.model:
            await self._load_model()

        features = self._extract_features(content)
        predictions = self.model.predict(features)

        return TagPrediction(
            predicted_tags=predictions['tags'],
            confidence_scores=predictions['scores'],
            learning_source='ml_model'
        )
```

### 4. ãƒ†ã‚¹ãƒˆå®Ÿè£…

```python
# tests/unit/test_tag_learner.py
class TestTagLearner:
    @pytest.fixture
    def learner(self, mock_settings):
        return TagLearner(mock_settings)

    @pytest.mark.asyncio
    async def test_collect_training_data(self, learner):
        # ãƒ‡ãƒ¼ã‚¿åé›†ã®ãƒ†ã‚¹ãƒˆ
        content = "ä»Šæ—¥ã¯#ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚° ã‚’å‹‰å¼·ã—ãŸ"
        user_tags = ["programming", "study"]
        ai_tags = ["programming", "learning"]

        await learner.collect_training_data(content, user_tags, ai_tags)

        assert len(learner.training_data) == 1
        assert learner.training_data[0].content == content
        assert learner.training_data[0].user_tags == user_tags

    @pytest.mark.asyncio
    async def test_tag_prediction(self, learner):
        # äºˆæ¸¬æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
        with patch.object(learner, 'model') as mock_model:
            mock_model.predict.return_value = {
                'tags': ['programming', 'study'],
                'scores': {'programming': 0.9, 'study': 0.8}
            }

            content = "Pythonã®å‹‰å¼·ã‚’ã—ãŸ"
            prediction = await learner.predict_tags(content)

            assert prediction.predicted_tags == ['programming', 'study']
            assert prediction.confidence_scores['programming'] == 0.9
```

### 5. çµ±åˆã¨ãƒ‡ãƒ—ãƒ­ã‚¤

```python
# src/ai/processor.py (æ—¢å­˜ã‚¯ãƒ©ã‚¹ã®æ‹¡å¼µ)
class AIProcessor:
    def __init__(self, settings: Settings):
        # æ—¢å­˜ã®åˆæœŸåŒ–...
        self.tag_learner = TagLearner(settings)

    async def analyze_content(self, content: str) -> ProcessingResult:
        # æ—¢å­˜ã®åˆ†æ...
        base_analysis = await self._base_analysis(content)

        # å­¦ç¿’æ¸ˆã¿ã‚¿ã‚°äºˆæ¸¬ã®è¿½åŠ 
        if self.settings.enable_tag_learning:
            tag_prediction = await self.tag_learner.predict_tags(content)
            base_analysis.tags.extend(tag_prediction.predicted_tags)
            base_analysis.confidence_scores = tag_prediction.confidence_scores

        return base_analysis
```

## âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°

```python
# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
import cProfile
import pstats
from functools import wraps

def profile_performance(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        profiler = cProfile.Profile()
        profiler.enable()

        try:
            result = await func(*args, **kwargs)
        finally:
            profiler.disable()

            # çµæœã®åˆ†æ
            stats = pstats.Stats(profiler)
            stats.sort_stats('cumulative')
            stats.print_stats(10)  # ãƒˆãƒƒãƒ—10ã‚’è¡¨ç¤º

        return result
    return wrapper

# ä½¿ç”¨ä¾‹
@profile_performance
async def process_large_batch(self, messages: List[str]):
    tasks = [self.process_message(msg) for msg in messages]
    return await asyncio.gather(*tasks)
```

### ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–

```python
# ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªå¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†
async def process_large_dataset(self, data_source: AsyncIterator[str]):
    """å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹ç‡çš„ã«å‡¦ç†ã™ã‚‹."""
    batch_size = 100
    batch = []

    async for item in data_source:
        batch.append(item)

        if len(batch) >= batch_size:
            await self._process_batch(batch)
            batch.clear()  # ãƒ¡ãƒ¢ãƒªè§£æ”¾

            # GCå¼·åˆ¶å®Ÿè¡Œï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
            import gc
            gc.collect()

    # æ®‹ã‚Šã®ãƒãƒƒãƒã‚’å‡¦ç†
    if batch:
        await self._process_batch(batch)
```

### éåŒæœŸæœ€é©åŒ–

```python
# åŠ¹ç‡çš„ãªä¸¦è¡Œå‡¦ç†
class OptimizedProcessor:
    def __init__(self, max_concurrent: int = 10):
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.rate_limiter = AsyncLimiter(15, 60)  # 15 requests per minute

    async def process_with_limits(self, content: str) -> ProcessingResult:
        async with self.semaphore:
            async with self.rate_limiter:
                return await self._actual_processing(content)

    async def process_batch_optimized(self,
                                    contents: List[str]) -> List[ProcessingResult]:
        """æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒƒãƒå‡¦ç†."""
        tasks = [
            self.process_with_limits(content)
            for content in contents
        ]

        # as_completed ã‚’ä½¿ç”¨ã—ã¦å®Œäº†æ¬¡ç¬¬å‡¦ç†
        results = []
        for coro in asyncio.as_completed(tasks):
            try:
                result = await coro
                results.append(result)
            except Exception as e:
                logger.error("Processing failed", error=str(e))
                results.append(None)

        return results
```

## ğŸ“š ãƒªã‚½ãƒ¼ã‚¹ã¨ãƒ„ãƒ¼ãƒ«

### æœ‰ç”¨ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª

```python
# pyproject.toml ã®æ¨å¥¨ä¾å­˜é–¢ä¿‚
[tool.uv.dependencies]
# éåŒæœŸå‡¦ç†
aiohttp = "^3.8.0"
aiofiles = "^23.0.0"

# ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
pydantic = "^2.0.0"

# ãƒ­ã‚°
structlog = "^23.0.0"
rich = "^13.0.0"

# ãƒ†ã‚¹ãƒˆ
pytest = "^7.0.0"
pytest-asyncio = "^0.21.0"
pytest-cov = "^4.0.0"

# é–‹ç™ºãƒ„ãƒ¼ãƒ«
ruff = "^0.0.280"
mypy = "^1.5.0"
pre-commit = "^3.0.0"
```

### é–‹ç™ºãƒ„ãƒ¼ãƒ«ã®è¨­å®š

```toml
# pyproject.toml
[tool.ruff]
select = ["E", "F", "W", "I", "N", "UP", "B", "S", "C4", "PIE", "T20"]
ignore = ["E501"]  # Line too long
line-length = 88
target-version = "py313"

[tool.mypy]
python_version = "3.13"
disallow_untyped_defs = true
disallow_any_generics = true
warn_unused_configs = true
warn_redundant_casts = true

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]
python_files = "test_*.py"
python_classes = "Test*"
python_functions = "test_*"
```

### æ¨å¥¨VS Codeæ‹¡å¼µæ©Ÿèƒ½

1. **Python** - Pythonè¨€èªã‚µãƒãƒ¼ãƒˆ
2. **Ruff** - ãƒªãƒ³ã‚¿ãƒ»ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿
3. **mypy Type Checker** - å‹ãƒã‚§ãƒƒã‚¯
4. **Python Test Explorer** - ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
5. **GitLens** - Gitçµ±åˆ
6. **Thunder Client** - API ãƒ†ã‚¹ãƒˆ
7. **YAML** - YAML ãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒãƒ¼ãƒˆ

## ğŸ“ ã‚µãƒãƒ¼ãƒˆã¨ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£

### è³ªå•ãƒ»ç›¸è«‡

- **GitHub Discussions**: ä¸€èˆ¬çš„ãªè³ªå•ãƒ»è­°è«–
- **GitHub Issues**: ãƒã‚°å ±å‘Šãƒ»æ©Ÿèƒ½è¦æ±‚
- **Code Review**: ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã®ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼

### ç¶™ç¶šçš„å­¦ç¿’

1. **Python éåŒæœŸãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°**
   - asyncioå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
   - "Using Asyncio in Python" by Caleb Hattingh

2. **Discord Boté–‹ç™º**
   - discord.pyå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
   - Discord Developer Portal

3. **AI/MLçµ±åˆ**
   - Google AI Platform ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
   - Hugging Face Transformers

4. **ãƒ†ã‚¹ãƒˆãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹**
   - pytestå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
   - "Test-Driven Development with Python" by Harry Percival

---

ã“ã®ã‚¬ã‚¤ãƒ‰ã‚’å‚è€ƒã«ã€åŠ¹ç‡çš„ã§ä¿å®ˆæ€§ã®é«˜ã„ã‚³ãƒ¼ãƒ‰ã®é–‹ç™ºã‚’é€²ã‚ã¦ãã ã•ã„ã€‚è³ªå•ã‚„æ”¹å–„ææ¡ˆãŒã‚ã‚Œã°ã€é æ…®ãªãGitHub Discussionsã§ç›¸è«‡ã—ã¦ãã ã•ã„ã€‚
