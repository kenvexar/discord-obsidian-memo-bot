"""
Obsidian vault file management system
"""

import asyncio
import re
import shutil
from datetime import datetime
from pathlib import Path
from typing import Any

import aiofiles
import yaml

from ..config.settings import get_settings
from ..utils.mixins import LoggerMixin
from .models import (
    FileOperation,
    NoteStatus,
    ObsidianNote,
    OperationType,
    VaultFolder,
    VaultStats,
)


class ObsidianFileManager(LoggerMixin):
    """Obsidian vault file management system"""

    def __init__(self, vault_path: Path | None = None, enable_local_data: bool = True):
        """
        Initialize Obsidian file manager

        Args:
            vault_path: Path to Obsidian vault (defaults to settings)
            enable_local_data: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹
        """
        if vault_path:
            self.vault_path = vault_path
        else:
            settings = get_settings()
            self.vault_path = settings.obsidian_vault_path

        # æ“ä½œå±¥æ­´
        self.operation_history: list[FileOperation] = []

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._folder_cache: set[Path] = set()
        self._stats_cache: VaultStats | None = None
        self._stats_cache_time: datetime | None = None

        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†
        self.local_data_manager = None
        if enable_local_data:
            from .local_data_manager import LocalDataManager

            self.local_data_manager = LocalDataManager(self.vault_path)

        self.logger.info(
            "Obsidian file manager initialized",
            vault_path=str(self.vault_path),
            local_data_enabled=enable_local_data,
        )

    async def initialize_vault(self) -> bool:
        """
        Vault æ§‹é€ ã‚’åˆæœŸåŒ–

        Returns:
            åˆæœŸåŒ–æˆåŠŸå¯å¦
        """
        try:
            # Vault ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
            self.vault_path.mkdir(parents=True, exist_ok=True)

            # å¿…è¦ãªãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã‚’ä½œæˆ
            await self._ensure_vault_structure()

            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
            await self._create_template_files()

            self.logger.info("Vault structure initialized successfully")
            return True

        except Exception as e:
            self.logger.error(
                "Failed to initialize vault structure", error=str(e), exc_info=True
            )
            return False

    async def save_note(self, note: ObsidianNote, overwrite: bool = False) -> bool:
        """
        ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜

        Args:
            note: ä¿å­˜ã™ã‚‹ãƒãƒ¼ãƒˆ
            overwrite: æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸Šæ›¸ãè¨±å¯

        Returns:
            ä¿å­˜æˆåŠŸå¯å¦
        """
        try:
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºä¿
            note.file_path.parent.mkdir(parents=True, exist_ok=True)

            # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            if note.file_path.exists() and not overwrite:
                self.logger.warning(
                    "File already exists",
                    file_path=str(note.file_path),
                    overwrite=overwrite,
                )
                return False

            # Markdown ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç”Ÿæˆ
            markdown_content = note.to_markdown()

            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            async with aiofiles.open(note.file_path, "w", encoding="utf-8") as f:
                await f.write(markdown_content)

            # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ›´æ–°
            if self.local_data_manager:
                self.local_data_manager.data_index.add_note(note)
                self.local_data_manager.data_index.save_indexes()

            # æ“ä½œè¨˜éŒ²
            operation = FileOperation(
                operation_type=OperationType.CREATE,
                file_path=note.file_path,
                success=True,
                metadata={
                    "note_title": note.title,
                    "category": note.category_from_filename,
                    "size_bytes": len(markdown_content.encode("utf-8")),
                },
            )
            self.operation_history.append(operation)

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ç„¡åŠ¹åŒ–
            self._invalidate_stats_cache()

            self.logger.info(
                "Note saved successfully",
                file_path=str(note.file_path),
                title=note.title,
                size_bytes=len(markdown_content.encode("utf-8")),
            )

            return True

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼è¨˜éŒ²
            operation = FileOperation(
                operation_type=OperationType.CREATE,
                file_path=note.file_path,
                success=False,
                error_message=str(e),
            )
            self.operation_history.append(operation)

            self.logger.error(
                "Failed to save note",
                file_path=str(note.file_path),
                error=str(e),
                exc_info=True,
            )

            return False

    async def load_note(self, file_path: Path) -> ObsidianNote | None:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿

        Args:
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            èª­ã¿è¾¼ã¾ã‚ŒãŸãƒãƒ¼ãƒˆï¼ˆå¤±æ•—æ™‚ã¯ None ï¼‰
        """
        try:
            if not file_path.exists() or not file_path.is_file():
                self.logger.warning("File not found", file_path=str(file_path))
                return None

            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            async with aiofiles.open(file_path, encoding="utf-8") as f:
                content = await f.read()

            # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ†é›¢
            frontmatter_data, markdown_content = self._parse_markdown_file(content)

            # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®å–å¾—
            stat = file_path.stat()
            created_at = datetime.fromtimestamp(stat.st_ctime)
            modified_at = datetime.fromtimestamp(stat.st_mtime)

            # NoteFrontmatter ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ
            from .models import NoteFrontmatter

            frontmatter = NoteFrontmatter(**frontmatter_data)

            note = ObsidianNote(
                filename=file_path.name,
                file_path=file_path,
                frontmatter=frontmatter,
                content=markdown_content,
                created_at=created_at,
                modified_at=modified_at,
            )

            self.logger.debug("Note loaded successfully", file_path=str(file_path))
            return note

        except Exception as e:
            self.logger.error(
                "Failed to load note",
                file_path=str(file_path),
                error=str(e),
                exc_info=True,
            )
            return None

    async def update_note(self, note: ObsidianNote) -> bool:
        """
        æ—¢å­˜ãƒãƒ¼ãƒˆã‚’æ›´æ–°

        Args:
            note: æ›´æ–°ã™ã‚‹ãƒãƒ¼ãƒˆ

        Returns:
            æ›´æ–°æˆåŠŸå¯å¦
        """
        try:
            # modified æ™‚åˆ»ã‚’æ›´æ–°
            note.modified_at = datetime.now()
            note.frontmatter.modified = note.modified_at.isoformat()

            # ä¿å­˜å®Ÿè¡Œ
            success = await self.save_note(note, overwrite=True)

            if success:
                # æ“ä½œè¨˜éŒ²ã‚’æ›´æ–°ã«å¤‰æ›´
                if self.operation_history:
                    self.operation_history[-1].operation_type = OperationType.UPDATE

                self.logger.info(
                    "Note updated successfully", file_path=str(note.file_path)
                )

            return success

        except Exception as e:
            self.logger.error(
                "Failed to update note",
                file_path=str(note.file_path),
                error=str(e),
                exc_info=True,
            )
            return False

    async def append_to_note(
        self, file_path: Path, content_to_append: str, separator: str = "\n\n"
    ) -> bool:
        """
        æ—¢å­˜ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿½è¨˜ï¼ˆé‡è¤‡é™¤å»æ©Ÿèƒ½ä»˜ãï¼‰

        Args:
            file_path: è¿½è¨˜å…ˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            content_to_append: è¿½è¨˜ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
            separator: æ—¢å­˜ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ã®åŒºåˆ‡ã‚Šæ–‡å­—

        Returns:
            è¿½è¨˜æˆåŠŸå¯å¦
        """
        try:
            # æ—¢å­˜ãƒãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿
            existing_note = await self.load_note(file_path)
            if not existing_note:
                self.logger.warning(
                    "Target note not found for append", file_path=str(file_path)
                )
                return False

            # é‡è¤‡ã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ URL è¦ç´„ã‚’é™¤å»
            cleaned_content = self._clean_duplicate_sections(
                content_to_append, existing_note.content
            )

            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿½è¨˜
            existing_note.content += separator + cleaned_content

            # æ›´æ–°æ™‚åˆ»ã‚’ç¾åœ¨æ™‚åˆ»ã«è¨­å®š
            existing_note.modified_at = datetime.now()
            existing_note.frontmatter.modified = existing_note.modified_at.isoformat()

            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãä¿å­˜
            success = await self.save_note(existing_note, overwrite=True)

            if success:
                # æ“ä½œè¨˜éŒ²ã‚’è¿½è¨˜ã«å¤‰æ›´
                if self.operation_history:
                    self.operation_history[-1].operation_type = OperationType.UPDATE
                    self.operation_history[-1].metadata = {
                        "note_title": existing_note.title,
                        "operation": "append",
                        "appended_content_length": len(cleaned_content),
                    }

                self.logger.info(
                    "Content appended to note successfully",
                    file_path=str(file_path),
                    content_length=len(cleaned_content),
                )

            return success

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼è¨˜éŒ²
            operation = FileOperation(
                operation_type=OperationType.UPDATE,
                file_path=file_path,
                success=False,
                error_message=str(e),
                metadata={"operation": "append"},
            )
            self.operation_history.append(operation)

            self.logger.error(
                "Failed to append content to note",
                file_path=str(file_path),
                error=str(e),
                exc_info=True,
            )

            return False

    def _clean_duplicate_sections(self, new_content: str, existing_content: str) -> str:
        """
        æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰é‡è¤‡ã™ã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é™¤å»

        Args:
            new_content: æ–°ã—ãè¿½åŠ ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
            existing_content: æ—¢å­˜ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„

        Returns:
            é‡è¤‡é™¤å»å¾Œã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        """
        try:
            # é‡è¤‡ã™ã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
            duplicate_patterns = [
                r"## ğŸ“… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿.*?(?=##|\Z)",  # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³
                r"## ğŸ”— é–¢é€£ãƒªãƒ³ã‚¯.*?(?=##|\Z)",  # é–¢é€£ãƒªãƒ³ã‚¯ã‚»ã‚¯ã‚·ãƒ§ãƒ³
                r"---\n\*ã“ã®ãƒãƒ¼ãƒˆã¯ Discord-Obsidian Memo Bot ã«ã‚ˆã£ã¦è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ\*",  # ãƒ•ãƒƒã‚¿ãƒ¼
                r"# ğŸ“\s*\n*",  # é‡è¤‡ã™ã‚‹ã‚¿ã‚¤ãƒˆãƒ«
            ]

            cleaned_content = new_content

            # å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã§é‡è¤‡ã‚’é™¤å»
            for pattern in duplicate_patterns:
                # æ—¢å­˜ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«åŒã˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒã‚ã‚‹å ´åˆã€æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰é™¤å»
                if re.search(pattern, existing_content, re.DOTALL):
                    cleaned_content = re.sub(
                        pattern, "", cleaned_content, flags=re.DOTALL
                    )

            # URL è¦ç´„ã®é‡è¤‡ã‚’é™¤å»ï¼ˆåŒã˜ URL ã®å ´åˆï¼‰
            existing_urls = re.findall(r"ğŸ”— (https?://[^\s]+)", existing_content)
            for url in existing_urls:
                # åŒã˜ URL ã®è¦ç´„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é™¤å»
                url_section_pattern = (
                    rf"## ğŸ“ URL è¦ç´„.*?### .*?\n ğŸ”— {re.escape(url)}.*?(?=##|\Z)"
                )
                cleaned_content = re.sub(
                    url_section_pattern, "", cleaned_content, flags=re.DOTALL
                )

            # ç©ºè¡Œã®æ•´ç†
            cleaned_content = re.sub(r"\n{3,}", "\n\n", cleaned_content)
            cleaned_content = cleaned_content.strip()

            # å®Œå…¨ã«ç©ºã«ãªã£ãŸå ´åˆã¯å…ƒã®ã‚¿ã‚¤ãƒˆãƒ«éƒ¨åˆ†ã®ã¿ä¿æŒ
            if not cleaned_content or cleaned_content.isspace():
                # æœ€å°é™ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆæ™‚åˆ»ã®ã¿ï¼‰ã‚’æŠ½å‡º
                timestamp_match = re.search(r"## \d{2}:\d{2}", new_content)
                if timestamp_match:
                    cleaned_content = timestamp_match.group(0)
                else:
                    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç”Ÿæˆ
                    current_time = datetime.now().strftime("%H:%M")
                    cleaned_content = f"## {current_time}"

            return cleaned_content

        except Exception as e:
            self.logger.warning("Failed to clean duplicate sections", error=str(e))
            return new_content  # å¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿”ã™

    async def save_or_append_daily_note(self, note: ObsidianNote) -> bool:
        """
        æ—¥åˆ¥ãƒãƒ¼ãƒˆã®ä¿å­˜ã¾ãŸã¯æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®è¿½è¨˜ï¼ˆæ”¹è‰¯ã•ã‚ŒãŸæ§‹é€ ï¼‰

        Args:
            note: ä¿å­˜/è¿½è¨˜ã™ã‚‹ãƒãƒ¼ãƒˆ

        Returns:
            ä¿å­˜/è¿½è¨˜æˆåŠŸå¯å¦
        """
        try:
            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if note.file_path.exists():
                # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆæ—¥ã‚’ãƒã‚§ãƒƒã‚¯
                existing_note = await self.load_note(note.file_path)
                if existing_note:
                    # åŒæ—¥ã§ã‚ã‚Œã°è¿½è¨˜
                    today = datetime.now().date()
                    existing_date = existing_note.created_at.date()

                    if existing_date == today:
                        self.logger.info(
                            "Appending to existing daily note",
                            file_path=str(note.file_path),
                            existing_date=str(existing_date),
                        )

                        # æ—¢å­˜ãƒãƒ¼ãƒˆã®æ§‹é€ ã‚’æ”¹å–„ï¼ˆåˆå›æ™‚ã®ã¿ï¼‰
                        if "## ğŸ’­ å†…å®¹" in existing_note.content:
                            existing_note.content = self._restructure_daily_note(
                                existing_note.content
                            )
                            await self.save_note(existing_note, overwrite=True)

                        # æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã®ã¿ã‚’æŠ½å‡º
                        content_text = note.content
                        content_match = re.search(
                            r"## ğŸ’­ å†…å®¹\s*\n(.*?)(?=\n##|\n\*|$)",
                            content_text,
                            re.DOTALL,
                        )
                        if content_match:
                            main_content = content_match.group(1).strip()
                            # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’é™¤å»
                            main_content = re.sub(
                                r"\*\*ã‚«ãƒ†ã‚´ãƒª\*\*:.*?(?=\n|$)", "", main_content
                            ).strip()
                        else:
                            main_content = "å†…å®¹ãªã—"

                        # æ™‚ç³»åˆ—ã‚¨ãƒ³ãƒˆãƒªã¨ã—ã¦è¿½è¨˜
                        timestamp = datetime.now().strftime("%H:%M")
                        append_content = f"## {timestamp}\n\n{main_content}"

                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›´å‰ã«æŒ¿å…¥
                        return await self._insert_before_metadata(
                            note.file_path, append_content
                        )
                    else:
                        self.logger.warning(
                            "Daily note exists but for different date",
                            file_path=str(note.file_path),
                            existing_date=str(existing_date),
                            today=str(today),
                        )
                        return False
                else:
                    self.logger.warning(
                        "Could not load existing daily note",
                        file_path=str(note.file_path),
                    )
                    return False
            else:
                # æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆæ™‚ã«æ§‹é€ ã‚’æ”¹å–„
                note.content = self._restructure_daily_note(note.content)
                return await self.save_note(note, overwrite=False)

        except Exception as e:
            self.logger.error(
                "Failed to save or append daily note",
                file_path=str(note.file_path),
                error=str(e),
                exc_info=True,
            )
            return False

    def _restructure_daily_note(self, content: str) -> str:
        """
        æ—¥åˆ¥ãƒãƒ¼ãƒˆã®æ§‹é€ ã‚’æ”¹å–„ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æœ«å°¾ã«ç§»å‹•ï¼‰

        Args:
            content: å…ƒã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„

        Returns:
            æ”¹å–„ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        """
        try:
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ãƒ•ãƒƒã‚¿ãƒ¼ã‚’æŠ½å‡º
            metadata_match = re.search(
                r"(## ğŸ“… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿.*?)(?=##|---|\Z)", content, re.DOTALL
            )
            links_match = re.search(
                r"(## ğŸ”— é–¢é€£ãƒªãƒ³ã‚¯.*?)(?=##|---|\Z)", content, re.DOTALL
            )
            footer_match = re.search(
                r"(---\n\*ã“ã®ãƒãƒ¼ãƒˆã¯ Discord-Obsidian Memo Bot.*?(?=##|\Z))",
                content,
                re.DOTALL,
            )

            metadata_section = metadata_match.group(1) if metadata_match else ""
            links_section = links_match.group(1) if links_match else ""
            footer_section = footer_match.group(1) if footer_match else ""

            # ãƒ¡ã‚¤ãƒ³å†…å®¹éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒªãƒ³ã‚¯ãƒ»ãƒ•ãƒƒã‚¿ãƒ¼ã‚’é™¤å»ï¼‰
            main_content = content
            if metadata_section:
                main_content = main_content.replace(metadata_section, "")
            if links_section:
                main_content = main_content.replace(links_section, "")
            if footer_section:
                main_content = main_content.replace(footer_section, "")

            # æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æ™‚ç³»åˆ—ã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆ
            content_match = re.search(
                r"## ğŸ’­ å†…å®¹\s*\n(.*?)(?=\n##|\Z)", main_content, re.DOTALL
            )
            if content_match:
                first_content = content_match.group(1).strip()
                # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’é™¤å»
                first_content = re.sub(
                    r"\*\*ã‚«ãƒ†ã‚´ãƒª\*\*:.*?(?=\n|$)", "", first_content
                ).strip()

                # ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—
                current_time = datetime.now().strftime("%H:%M")

                # æ–°ã—ã„æ§‹é€ ã§å†æ§‹ç¯‰
                restructured = f"""# ğŸ“ æ—¥æ¬¡ãƒãƒ¼ãƒˆ

## {current_time}

{first_content}

{metadata_section}

{links_section}

{footer_section}"""
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                restructured = main_content

            # ä¸è¦ãªç©ºè¡Œã‚’æ•´ç†
            restructured = re.sub(r"\n{3,}", "\n\n", restructured)
            restructured = restructured.strip()

            return restructured

        except Exception as e:
            self.logger.warning("Failed to restructure daily note", error=str(e))
            return content

    async def _insert_before_metadata(
        self, file_path: Path, content_to_insert: str
    ) -> bool:
        """
        ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›´å‰ã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŒ¿å…¥

        Args:
            file_path: å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            content_to_insert: æŒ¿å…¥ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„

        Returns:
            æŒ¿å…¥æˆåŠŸå¯å¦
        """
        try:
            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            existing_note = await self.load_note(file_path)
            if not existing_note:
                return False

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
            metadata_pattern = r"(## ğŸ“… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿.*)"
            metadata_match = re.search(
                metadata_pattern, existing_note.content, re.DOTALL
            )

            if metadata_match:
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å‰ã«æŒ¿å…¥
                metadata_start = metadata_match.start()
                new_content = (
                    existing_note.content[:metadata_start]
                    + content_to_insert
                    + "\n\n"
                    + existing_note.content[metadata_start:]
                )
            else:
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æœ«å°¾ã«è¿½åŠ 
                new_content = existing_note.content + "\n\n" + content_to_insert

            existing_note.content = new_content
            existing_note.modified_at = datetime.now()
            existing_note.frontmatter.modified = existing_note.modified_at.isoformat()

            return await self.save_note(existing_note, overwrite=True)

        except Exception as e:
            self.logger.error(
                "Failed to insert content before metadata",
                file_path=str(file_path),
                error=str(e),
                exc_info=True,
            )
            return False

    async def delete_note(self, file_path: Path, to_archive: bool = True) -> bool:
        """
        ãƒãƒ¼ãƒˆã‚’å‰Šé™¤ã¾ãŸã¯ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–

        Args:
            file_path: å‰Šé™¤ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            to_archive: ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã™ã‚‹ã‹ã©ã†ã‹

        Returns:
            å‰Šé™¤æˆåŠŸå¯å¦
        """
        try:
            if not file_path.exists():
                self.logger.warning(
                    "File not found for deletion", file_path=str(file_path)
                )
                return False

            success = False
            operation_type = (
                OperationType.ARCHIVE if to_archive else OperationType.DELETE
            )

            if to_archive:
                # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•
                archive_folder = self.vault_path / VaultFolder.ARCHIVE.value
                archive_folder.mkdir(parents=True, exist_ok=True)

                # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«åã®ç”Ÿæˆ
                timestamp = datetime.now().strftime("%Y%m%d%H%M")
                archived_filename = f"{timestamp}_archived_{file_path.name}"
                archive_path = archive_folder / archived_filename

                # ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•
                shutil.move(str(file_path), str(archive_path))

                self.logger.info(
                    "Note archived successfully",
                    original_path=str(file_path),
                    archive_path=str(archive_path),
                )
                success = True

            else:
                # å®Œå…¨å‰Šé™¤
                file_path.unlink()

                self.logger.info("Note deleted successfully", file_path=str(file_path))
                success = True

            # æ“ä½œè¨˜éŒ²
            operation = FileOperation(
                operation_type=operation_type, file_path=file_path, success=success
            )
            self.operation_history.append(operation)

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ç„¡åŠ¹åŒ–
            self._invalidate_stats_cache()

            return success

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼è¨˜éŒ²
            operation = FileOperation(
                operation_type=operation_type,
                file_path=file_path,
                success=False,
                error_message=str(e),
            )
            self.operation_history.append(operation)

            self.logger.error(
                "Failed to delete/archive note",
                file_path=str(file_path),
                to_archive=to_archive,
                error=str(e),
                exc_info=True,
            )

            return False

    async def search_notes(
        self,
        query: str | None = None,
        folder: VaultFolder | None = None,
        status: NoteStatus | None = None,
        tags: list[str] | None = None,
        date_from: datetime | None = None,
        date_to: datetime | None = None,
        limit: int = 50,
    ) -> list[ObsidianNote]:
        """
        ãƒãƒ¼ãƒˆæ¤œç´¢

        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            folder: ãƒ•ã‚©ãƒ«ãƒ€æŒ‡å®š
            status: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æŒ‡å®š
            tags: ã‚¿ã‚°æŒ‡å®š
            date_from: é–‹å§‹æ—¥
            date_to: çµ‚äº†æ—¥
            limit: çµæœä¸Šé™

        Returns:
            æ¤œç´¢çµæœã®ãƒãƒ¼ãƒˆãƒªã‚¹ãƒˆ
        """
        try:
            results: list[ObsidianNote] = []
            search_path = self.vault_path

            # ãƒ•ã‚©ãƒ«ãƒ€æŒ‡å®šãŒã‚ã‚‹å ´åˆ
            if folder:
                search_path = self.vault_path / folder.value
                if not search_path.exists():
                    return []

            # .md ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«æ¤œç´¢
            for md_file in search_path.rglob("*.md"):
                if len(results) >= limit:
                    break

                # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã¯é™¤å¤–
                if VaultFolder.TEMPLATES.value in str(
                    md_file.relative_to(self.vault_path)
                ):
                    continue

                note = await self.load_note(md_file)
                if not note:
                    continue

                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if not self._matches_search_criteria(
                    note, query, status, tags, date_from, date_to
                ):
                    continue

                results.append(note)

            # ä½œæˆæ—¥æ™‚ã§é€†é †ã‚½ãƒ¼ãƒˆ
            results.sort(key=lambda n: n.created_at, reverse=True)

            self.logger.debug(
                "Note search completed",
                query=query,
                results_count=len(results),
                limit=limit,
            )

            return results

        except Exception as e:
            self.logger.error(
                "Failed to search notes", query=query, error=str(e), exc_info=True
            )
            return []

    async def get_vault_stats(self, force_refresh: bool = False) -> VaultStats:
        """
        Vault çµ±è¨ˆæƒ…å ±ã‚’å–å¾—

        Args:
            force_refresh: å¼·åˆ¶ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥

        Returns:
            Vault çµ±è¨ˆæƒ…å ±
        """
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ï¼ˆ 5 åˆ†é–“æœ‰åŠ¹ï¼‰
            if (
                not force_refresh
                and self._stats_cache
                and self._stats_cache_time
                and (datetime.now() - self._stats_cache_time).seconds < 300
            ):
                return self._stats_cache

            stats = VaultStats()

            # .md ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«æ¤œç´¢
            for md_file in self.vault_path.rglob("*.md"):
                # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã¯é™¤å¤–
                if VaultFolder.TEMPLATES.value in str(
                    md_file.relative_to(self.vault_path)
                ):
                    continue

                # åŸºæœ¬çµ±è¨ˆ
                stats.total_notes += 1
                stats.total_size_bytes += md_file.stat().st_size

                # ãƒ•ã‚©ãƒ«ãƒ€åˆ¥çµ±è¨ˆ
                relative_path = md_file.relative_to(self.vault_path)
                folder_name = (
                    str(relative_path.parts[0]) if relative_path.parts else "root"
                )
                stats.notes_by_folder[folder_name] = (
                    stats.notes_by_folder.get(folder_name, 0) + 1
                )

                # æ—¥ä»˜åˆ¥çµ±è¨ˆ
                created_time = datetime.fromtimestamp(md_file.stat().st_ctime)
                today = datetime.now().date()
                created_date = created_time.date()

                if created_date == today:
                    stats.notes_created_today += 1

                if (today - created_date).days <= 7:
                    stats.notes_created_this_week += 1

                if (
                    created_date.month == today.month
                    and created_date.year == today.year
                ):
                    stats.notes_created_this_month += 1

            # ãƒãƒ¼ãƒˆè©³ç´°çµ±è¨ˆï¼ˆé‡ã„å‡¦ç†ãªã®ã§ä¸€éƒ¨ã®ã¿ï¼‰
            recent_notes = await self.search_notes(limit=100)

            for note in recent_notes:
                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥çµ±è¨ˆ
                status_name = note.frontmatter.status.value
                stats.notes_by_status[status_name] = (
                    stats.notes_by_status.get(status_name, 0) + 1
                )

                # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
                if note.frontmatter.ai_category:
                    category = note.frontmatter.ai_category
                    stats.notes_by_category[category] = (
                        stats.notes_by_category.get(category, 0) + 1
                    )

                # AI å‡¦ç†çµ±è¨ˆ
                if note.frontmatter.ai_processed:
                    stats.ai_processed_notes += 1
                    if note.frontmatter.ai_processing_time:
                        stats.total_ai_processing_time += (
                            note.frontmatter.ai_processing_time
                        )

                # ã‚¿ã‚°çµ±è¨ˆ
                for tag in note.frontmatter.ai_tags + note.frontmatter.tags:
                    clean_tag = tag.lstrip("#")
                    stats.most_common_tags[clean_tag] = (
                        stats.most_common_tags.get(clean_tag, 0) + 1
                    )

            # å¹³å‡ AI å‡¦ç†æ™‚é–“
            if stats.ai_processed_notes > 0:
                stats.average_ai_processing_time = (
                    stats.total_ai_processing_time / stats.ai_processed_notes
                )

            # ã‚¿ã‚°ã‚’é »åº¦é †ã«ã‚½ãƒ¼ãƒˆï¼ˆä¸Šä½ 20 å€‹ï¼‰
            sorted_tags = sorted(
                stats.most_common_tags.items(), key=lambda x: x[1], reverse=True
            )[:20]
            stats.most_common_tags = dict(sorted_tags)

            stats.last_updated = datetime.now()

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°
            self._stats_cache = stats
            self._stats_cache_time = datetime.now()

            self.logger.info(
                "Vault stats collected",
                total_notes=stats.total_notes,
                total_size_mb=stats.total_size_bytes / (1024 * 1024),
                ai_processed=stats.ai_processed_notes,
            )

            return stats

        except Exception as e:
            self.logger.error(
                "Failed to collect vault stats", error=str(e), exc_info=True
            )
            return VaultStats()

    async def backup_vault(self, backup_path: Path) -> bool:
        """
        Vault ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ

        Args:
            backup_path: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å…ˆãƒ‘ã‚¹

        Returns:
            ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆåŠŸå¯å¦
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_dir = backup_path / f"obsidian_vault_backup_{timestamp}"

            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚³ãƒ”ãƒ¼
            await asyncio.to_thread(shutil.copytree, self.vault_path, backup_dir)

            self.logger.info(
                "Vault backup completed",
                backup_path=str(backup_dir),
                vault_path=str(self.vault_path),
            )

            return True

        except Exception as e:
            self.logger.error(
                "Failed to backup vault",
                backup_path=str(backup_path),
                error=str(e),
                exc_info=True,
            )
            return False

    def get_operation_history(self, limit: int = 50) -> list[FileOperation]:
        """æ“ä½œå±¥æ­´ã‚’å–å¾—"""
        return self.operation_history[-limit:]

    def clear_operation_history(self) -> None:
        """æ“ä½œå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"""
        self.operation_history.clear()
        self.logger.info("Operation history cleared")

    async def _ensure_vault_structure(self) -> None:
        """Vault æ§‹é€ ã‚’ç¢ºä¿"""
        folders_to_create = [
            VaultFolder.INBOX,
            VaultFolder.PROJECTS,
            VaultFolder.DAILY_NOTES,
            VaultFolder.IDEAS,
            VaultFolder.ARCHIVE,
            VaultFolder.RESOURCES,
            VaultFolder.FINANCE,
            VaultFolder.TASKS,
            VaultFolder.HEALTH,
            VaultFolder.KNOWLEDGE,  # LEARNING â†’ KNOWLEDGE ã«å¤‰æ›´
            VaultFolder.META,
            VaultFolder.TEMPLATES,
            VaultFolder.ATTACHMENTS,
            VaultFolder.IMAGES,
            VaultFolder.AUDIO,
            VaultFolder.DOCUMENTS,
            VaultFolder.OTHER_FILES,
        ]

        for folder in folders_to_create:
            folder_path = self.vault_path / folder.value
            folder_path.mkdir(parents=True, exist_ok=True)
            self._folder_cache.add(folder_path)

        # å¹´æœˆãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆï¼ˆç¾åœ¨å¹´ã®å‰å¾Œ 1 å¹´ï¼‰
        current_year = datetime.now().year
        for year in range(current_year - 1, current_year + 2):
            year_folder = self.vault_path / VaultFolder.DAILY_NOTES.value / str(year)
            year_folder.mkdir(parents=True, exist_ok=True)

            # æœˆãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆ
            for month in range(1, 13):
                month_name = datetime(year, month, 1).strftime("%m-%B")
                month_folder = year_folder / month_name
                month_folder.mkdir(parents=True, exist_ok=True)

    async def _create_template_files(self) -> None:
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        templates_dir = self.vault_path / VaultFolder.TEMPLATES.value

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒãƒ¼ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        message_template_content = """# {{title}}

## ğŸ“ è¦ç´„
{{ai_summary}}

## ğŸ’¬ å…ƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
```
{{original_content}}
```

## ğŸ·ï¸ ã‚¿ã‚°
{{ai_tags}}

## ğŸ“‚ åˆ†é¡
- **ã‚«ãƒ†ã‚´ãƒª**: {{ai_category}}
- **ä¿¡é ¼åº¦**: {{ai_confidence}}

## ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«
{{attachments}}

## ğŸ”— é–¢é€£ãƒªãƒ³ã‚¯
- [Discord Message]({{discord_link}})
- **ãƒãƒ£ãƒ³ãƒãƒ«**: #{{channel_name}}

## ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
- **ä½œæˆè€…**: {{author_name}}
- **ä½œæˆæ—¥æ™‚**: {{created_time}}
- **AI å‡¦ç†æ™‚é–“**: {{processing_time}}ms

---
*ã“ã®ãƒãƒ¼ãƒˆã¯ Discord-Obsidian Memo Bot ã«ã‚ˆã£ã¦è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*"""

        message_template_path = templates_dir / "message_note_template.md"
        if not message_template_path.exists():
            async with aiofiles.open(message_template_path, "w", encoding="utf-8") as f:
                await f.write(message_template_content)

        # æ—¥æ¬¡ãƒãƒ¼ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        daily_template_content = """# Daily Note - {{date}}

## ğŸ“Š ä»Šæ—¥ã®çµ±è¨ˆ
- **ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°**: {{total_messages}}
- **AI å‡¦ç†æ¸ˆã¿**: {{processed_messages}}
- **å‡¦ç†æ™‚é–“åˆè¨ˆ**: {{ai_time_total}}ms

## ğŸ“ ä»Šæ—¥ã®ãƒ¡ãƒ¢

### ä»•äº‹ ({{work_count}}ä»¶)
{{work_notes}}

### å­¦ç¿’ ({{learning_count}}ä»¶)
{{learning_notes}}

### ç”Ÿæ´» ({{life_count}}ä»¶)
{{life_notes}}

### ã‚¢ã‚¤ãƒ‡ã‚¢ ({{ideas_count}}ä»¶)
{{ideas_notes}}

## ğŸ·ï¸ ä»Šæ—¥ã®ã‚¿ã‚°
{{daily_tags}}

## ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«
{{daily_attachments}}

---
*ã“ã®ãƒãƒ¼ãƒˆã¯æ¯æ—¥è‡ªå‹•æ›´æ–°ã•ã‚Œã¾ã™*"""

        daily_template_path = templates_dir / "daily_note_template.md"
        if not daily_template_path.exists():
            async with aiofiles.open(daily_template_path, "w", encoding="utf-8") as f:
                await f.write(daily_template_content)

    def _parse_markdown_file(self, content: str) -> tuple[dict[str, Any], str]:
        """Markdown ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†é›¢"""

        frontmatter_data: dict[str, Any] = {}
        markdown_content = content

        # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã®æ¤œå‡º
        if content.startswith("---\n"):
            parts = content.split("---\n", 2)
            if len(parts) >= 3:
                try:
                    frontmatter_data = yaml.safe_load(parts[1]) or {}
                    markdown_content = parts[2]
                except yaml.YAMLError as e:
                    self.logger.warning(
                        "Failed to parse YAML frontmatter", error=str(e)
                    )

        return frontmatter_data, markdown_content

    def _matches_search_criteria(
        self,
        note: ObsidianNote,
        query: str | None,
        status: NoteStatus | None,
        tags: list[str] | None,
        date_from: datetime | None,
        date_to: datetime | None,
    ) -> bool:
        """æ¤œç´¢æ¡ä»¶ã«ãƒãƒƒãƒã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""

        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ã‚£ãƒ«ã‚¿
        if status and note.frontmatter.status != status:
            return False

        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿
        if date_from and note.created_at < date_from:
            return False

        if date_to and note.created_at > date_to:
            return False

        # ã‚¿ã‚°ãƒ•ã‚£ãƒ«ã‚¿
        if tags:
            note_tags = set(
                note.frontmatter.tags
                + [tag.lstrip("#") for tag in note.frontmatter.ai_tags]
            )
            if not any(tag in note_tags for tag in tags):
                return False

        # ã‚¯ã‚¨ãƒªãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€ã‚¿ã‚°ã€è¦ç´„ã‚’æ¤œç´¢ï¼‰
        if query:
            query_lower = query.lower()
            searchable_text = " ".join(
                [
                    note.title.lower(),
                    note.content.lower(),
                    " ".join(note.frontmatter.tags),
                    " ".join(note.frontmatter.ai_tags),
                    note.frontmatter.ai_summary or "",
                ]
            )

            if query_lower not in searchable_text:
                return False

        return True

    def _invalidate_stats_cache(self) -> None:
        """çµ±è¨ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡åŠ¹åŒ–"""
        self._stats_cache = None
        self._stats_cache_time = None

    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ¡ã‚½ãƒƒãƒ‰

    async def initialize_local_data(self) -> bool:
        """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–"""
        if not self.local_data_manager:
            self.logger.warning("Local data manager not enabled")
            return False

        return await self.local_data_manager.initialize()

    async def create_vault_snapshot(self, name: str | None = None) -> Path | None:
        """Vault ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä½œæˆ"""
        if not self.local_data_manager:
            self.logger.warning("Local data manager not enabled")
            return None

        return await self.local_data_manager.create_snapshot(name)

    async def restore_vault_snapshot(self, snapshot_file: Path) -> bool:
        """ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰ Vault ã‚’å¾©å…ƒ"""
        if not self.local_data_manager:
            self.logger.warning("Local data manager not enabled")
            return False

        success = await self.local_data_manager.restore_snapshot(snapshot_file)
        if success:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
            self._invalidate_stats_cache()

        return success

    async def export_vault_data(self, format: str = "json") -> Path | None:
        """Vault ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        if not self.local_data_manager:
            self.logger.warning("Local data manager not enabled")
            return None

        return await self.local_data_manager.export_vault_data(format)

    async def sync_with_remote(
        self, remote_path: Path, direction: str = "both"
    ) -> bool:
        """ãƒªãƒ¢ãƒ¼ãƒˆã¨åŒæœŸ"""
        if not self.local_data_manager:
            self.logger.warning("Local data manager not enabled")
            return False

        success = await self.local_data_manager.sync_with_remote(remote_path, direction)
        if success:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
            self._invalidate_stats_cache()

        return success

    async def rebuild_local_index(self) -> bool:
        """ãƒ­ãƒ¼ã‚«ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰"""
        if not self.local_data_manager:
            self.logger.warning("Local data manager not enabled")
            return False

        return await self.local_data_manager.rebuild_index()

    def search_notes_fast(
        self,
        query: str | None = None,
        tags: list[str] | None = None,
        status: str | None = None,
        category: str | None = None,
        limit: int = 50,
    ) -> list[Path]:
        """é«˜é€Ÿãƒãƒ¼ãƒˆæ¤œç´¢ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨ï¼‰"""
        if not self.local_data_manager:
            self.logger.warning(
                "Local data manager not enabled, falling back to regular search"
            )
            return []

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ã®æ¤œç´¢
        file_keys = self.local_data_manager.data_index.search_notes(
            query=query, tags=tags, status=status, category=category, limit=limit
        )

        # ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
        return [self.vault_path / file_key for file_key in file_keys]

    async def get_local_data_stats(self) -> dict:
        """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        if not self.local_data_manager:
            return {"local_data_enabled": False}

        stats = await self.local_data_manager.get_local_stats()
        stats["local_data_enabled"] = True
        return stats

    async def auto_backup_if_needed(self) -> bool:
        """å¿…è¦ã«å¿œã˜ã¦è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ"""
        if not self.local_data_manager:
            return False

        try:
            # æœ€å¾Œã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆæ™‚åˆ»ã‚’ãƒã‚§ãƒƒã‚¯
            snapshots_dir = self.local_data_manager.snapshots_dir
            if not snapshots_dir.exists():
                # åˆå›ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
                snapshot = await self.create_vault_snapshot("auto_backup_initial")
                return snapshot is not None

            # æœ€æ–°ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ç¢ºèª
            snapshots = list(snapshots_dir.glob("*.tar.gz"))
            if not snapshots:
                # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆãŒå­˜åœ¨ã—ãªã„
                snapshot = await self.create_vault_snapshot("auto_backup")
                return snapshot is not None

            # æœ€æ–°ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆæ™‚åˆ»
            latest_snapshot = max(snapshots, key=lambda f: f.stat().st_mtime)
            last_backup_time = datetime.fromtimestamp(latest_snapshot.stat().st_mtime)

            # 24 æ™‚é–“ä»¥ä¸ŠçµŒéã—ã¦ã„ã‚Œã°è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            if (datetime.now() - last_backup_time).total_seconds() > 24 * 3600:
                snapshot = await self.create_vault_snapshot("auto_backup_daily")
                return snapshot is not None

            return True

        except Exception as e:
            self.logger.error(
                "Failed to perform auto backup", error=str(e), exc_info=True
            )
            return False
